%%%%%%%%%%%%%%%%%%%% MetalFish Paper %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% MetalFish: GPU-Accelerated Chess Engine on Apple Silicon
%
%%%%%%%%%%%%%%%% Springer %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass{svproc}

\usepackage{url}
\def\UrlFont{\rmfamily}
\usepackage{graphicx}
\usepackage{float}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{booktabs}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}

% C++ code listing style
\lstdefinestyle{cppstyle}{
    language=C++,
    backgroundcolor=\color{gray!5},
    basicstyle=\ttfamily\footnotesize,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    numberstyle=\tiny\color{gray},
    showstringspaces=false,
    tabsize=2,
    frame=single,
    keywordstyle=\color{blue!70!black},
    commentstyle=\color{green!50!black},
    stringstyle=\color{red!60!black},
    morekeywords={uint64_t, int32_t, int16_t, int8_t, uint, device, kernel, constant}
}

\begin{document}
\mainmatter

\title{MetalFish: GPU-Accelerated NNUE Evaluation\\on Apple Silicon}

\titlerunning{MetalFish: GPU NNUE on Apple Silicon}

\author{Nripesh Niketan\inst{1}}

\authorrunning{N. Niketan}

\institute{Independent Researcher\\
\email{nripesh14@gmail.com}}

\maketitle

\begin{abstract}
We present MetalFish, a GPU-accelerated chess engine leveraging Apple Silicon's unified memory architecture for NNUE evaluation. Through systematic benchmarking on M2 Max, we demonstrate: (1) single-position (N=1) blocking latency of 285~$\mu$s median, (2) per-position cost of 0.4~$\mu$s at batch size 4096, (3) true single-dispatch batching with up to 565$\times$ speedup over sequential dispatches at N=1024, and (4) adaptive kernel selection with dual-perspective feature transformation, zero-copy buffer management, and asynchronous evaluation support. We support 64 features per perspective, and observed maximum 30 in our dataset. While synchronous blocking dispatch overhead (148~$\mu$s) makes single-position GPU evaluation unsuitable for alpha-beta search without speculative evaluation, batch evaluation becomes throughput-competitive at $N \geq 512$, enabling efficient bulk analysis and MCTS-style evaluation.

\keywords{Chess Engine, GPU Computing, Metal, NNUE, Apple Silicon, Unified Memory}
\end{abstract}

\section{Introduction}

Modern chess engines combine alpha-beta search with neural network evaluation (NNUE) to achieve superhuman playing strength. While GPU acceleration has proven effective for batch-oriented algorithms like Monte Carlo Tree Search in Leela Chess Zero~\cite{LeelaChessZero2024}, its applicability to traditional alpha-beta search remains challenging due to sequential evaluation patterns.

Apple Silicon's unified memory architecture eliminates explicit CPU-GPU memory transfers, potentially reducing the overhead that has historically limited GPU adoption in alpha-beta engines. This paper presents MetalFish, a GPU-accelerated chess engine that explores the practical limits of GPU evaluation on Apple Silicon.

\subsection{Contributions}

\begin{enumerate}
\item \textbf{Optimized GPU NNUE implementation}: We achieve 285~$\mu$s median single-position blocking latency and 0.4~$\mu$s per position at batch size 4096.

\item \textbf{Adaptive kernel selection}: We implement strategy-based kernel dispatch that selects dual-perspective or single-perspective kernels based on batch size for optimal performance.

\item \textbf{Zero-copy buffer management}: Pre-allocated staging buffers eliminate per-call allocations, writing directly to unified memory.

\item \textbf{Asynchronous evaluation}: We provide completion handler support for CPU/GPU work overlap.

\item \textbf{Verified true batching}: We demonstrate single-dispatch batching achieving up to 565$\times$ speedup over sequential dispatches at batch size 1024.

\item \textbf{Comprehensive benchmarking}: We provide detailed stage breakdowns, latency percentiles, correctness verification, and scaling analysis across batch sizes 1--4096.
\end{enumerate}

\section{Background}

\subsection{NNUE Architecture}

Stockfish's NNUE~\cite{Stockfish2024,Nasu2018} uses HalfKAv2\_hm features with sparse input and efficient incremental updates. Table~\ref{tab:nnue_arch} summarizes the architecture.

\begin{table}[t]
\caption{NNUE Network Architecture}
\label{tab:nnue_arch}
\centering
\begin{tabular}{lrr}
\toprule
Component & Big Network & Small Network \\
\midrule
Feature set & HalfKAv2\_hm & HalfKAv2\_hm \\
Input features & 45,056 & 22,528 \\
Hidden dimension & 1,024 & 128 \\
FC0 output & 15 (+1 skip) & 15 (+1 skip) \\
FC1 output & 32 & 32 \\
FC2 output & 1 & 1 \\
Layer stacks (buckets) & 8 & 8 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Feature requirements}: HalfKAv2\_hm generates one feature per non-king piece from each perspective. A position with 30 pieces (excluding 2 kings) generates up to 30 features per perspective. We support 64 features per perspective, providing headroom for all legal positions.

\subsection{Metal Compute Model}

Apple Metal~\cite{AppleMetal2024} provides GPU compute through command buffers with unified memory access. Key characteristics:
\begin{itemize}
\item \textbf{Unified memory}: CPU and GPU share the same physical memory, eliminating explicit transfers
\item \textbf{Command buffer lifecycle}: Allocation, encoding, submission, and synchronization
\item \textbf{Threadgroup memory}: Fast on-chip memory for inter-thread communication
\item \textbf{SIMD groups}: 32-wide SIMD execution on Apple GPUs
\item \textbf{Completion handlers}: Asynchronous notification of GPU work completion
\end{itemize}

\section{System Architecture}

\subsection{GPU Constants and Limits}

Table~\ref{tab:gpu_constants} shows the key GPU configuration parameters.

\begin{table}[t]
\caption{GPU Configuration Constants}
\label{tab:gpu_constants}
\centering
\begin{tabular}{lr}
\toprule
Parameter & Value \\
\midrule
Max batch size & 4,096 \\
Max features per perspective & 64 \\
Max total features & 128 \\
Threadgroup size & 256 \\
SIMD group size & 32 \\
Forward pass threads & 64 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Adaptive Kernel Selection}

We implement strategy-based kernel selection through the \texttt{GPUTuningParams} structure:

\begin{lstlisting}[style=cppstyle,caption={Evaluation strategy selection}]
enum class EvalStrategy {
  CPU_FALLBACK,      // batch < 4
  GPU_STANDARD,      // batch < 64
  GPU_SIMD,          // batch >= 64
  GPU_FEATURE_EXTRACT // batch >= 2048
};

EvalStrategy select_strategy(int batch_size) {
  if (batch_size < min_batch_for_gpu)
    return CPU_FALLBACK;
  if (batch_size >= simd_threshold)
    return GPU_SIMD;
  return GPU_STANDARD;
}
\end{lstlisting}

For batches $\geq 64$, we use the dual-perspective kernel that processes both white and black perspectives in a single 3D dispatch, reducing kernel launch overhead.

\subsection{Zero-Copy Buffer Management}

We pre-allocate all working buffers at initialization, eliminating per-call \texttt{std::vector} allocations:

\begin{lstlisting}[style=cppstyle,caption={Direct buffer writes via unified memory}]
// Get pointers to pre-allocated GPU buffers
int32_t* white_features_ptr = 
    static_cast<int32_t*>(white_features_buffer_->data());
uint32_t* white_counts_ptr = 
    static_cast<uint32_t*>(white_counts_buffer_->data());

// Write directly to unified memory (zero-copy)
for (int i = 0; i < batch_size; i++) {
  white_offsets_ptr[i] = white_feature_idx;
  // Extract features directly into GPU buffer
  white_features_ptr[white_feature_idx++] = feat;
}
\end{lstlisting}

\subsection{Kernel Optimizations}

We implement three key optimizations in our Metal compute kernels:

\textbf{1. Dual-perspective feature transformation}: For batches $\geq 64$, we use a 3D dispatch that processes both perspectives simultaneously:

\begin{lstlisting}[style=cppstyle,caption={Dual-perspective kernel dispatch}]
// 3D dispatch: (hidden_dim, 2 perspectives, batch_size)
encoder->dispatch_threads(hidden_dim, 2, batch_size);
\end{lstlisting}

\textbf{2. Unrolled accumulation}: The forward pass uses 8-way unrolled loops for the FC0 layer, reducing loop overhead and enabling instruction-level parallelism.

\textbf{3. Threadgroup memory}: Intermediate results (FC0 outputs, skip connections) are stored in threadgroup memory, enabling efficient inter-thread communication without global memory round-trips.

\subsection{Asynchronous Evaluation}

We provide completion handler support for overlapping CPU and GPU work:

\begin{lstlisting}[style=cppstyle,caption={Asynchronous batch evaluation}]
bool evaluate_batch_async(
    GPUEvalBatch& batch,
    std::function<void(bool)> completion_handler,
    bool use_big_network = true);

// Usage: CPU can prepare next batch while GPU works
gpu_manager.evaluate_batch_async(batch, [](bool ok) {
  // Called when GPU completes
  process_results(batch.positional_scores);
});
\end{lstlisting}

\subsection{Batch Evaluation Pipeline}

Algorithm~\ref{alg:batch} shows the optimized batch evaluation pipeline.

\begin{algorithm}[t]
\caption{GPU Batch NNUE Evaluation}
\label{alg:batch}
\begin{algorithmic}[1]
\Require Batch of $N$ positions
\Ensure Evaluation scores for all positions
\State \textbf{// Stage 1: Strategy selection}
\State $strategy \gets$ \Call{SelectStrategy}{$N$}
\If{$strategy = $ CPU\_FALLBACK}
    \State \Return CPU evaluation
\EndIf
\State \textbf{// Stage 2: Feature extraction (direct to GPU buffers)}
\For{each position}
    \State Write features directly to unified memory buffers
\EndFor
\State \textbf{// Stage 3: GPU evaluation (single command buffer)}
\If{$N \geq 64$}
    \State \Call{DispatchThreads}{$hidden\_dim, 2, N$} \Comment{Dual-perspective}
\Else
    \State \Call{DispatchThreads}{$hidden\_dim, N$} \Comment{Single-perspective}
\EndIf
\State \Call{Barrier}{}
\State \Call{DispatchThreadgroups}{$N$, threads=64} \Comment{Forward pass}
\State \Call{SubmitAndWait}{}
\State \Return scores from output buffer
\end{algorithmic}
\end{algorithm}

\section{Experimental Methodology}

\subsection{Hardware and Software}

\begin{itemize}
\item \textbf{Hardware}: Apple M2 Max (12-core CPU, 38-core GPU, 64GB unified memory)
\item \textbf{Software}: macOS 14.0, Xcode 15.0, Metal 3.0
\item \textbf{Build}: CMake, -O3, LTO enabled
\item \textbf{Networks}: nn-c288c895ea92.nnue (125MB), nn-37f18f62d772.nnue (6MB)
\end{itemize}

\subsection{Benchmark Dataset}

Our benchmark uses 8 unique FEN positions representing diverse game phases (opening, middlegame, endgame), cycled to create 2048 test positions. Piece counts range from 2 to 32, with most positions containing 28--32 pieces.

\subsection{Timing Methodology}

All measurements use \texttt{std::chrono::high\_resolution\_clock}:
\begin{itemize}
\item \textbf{Warmup}: 100 iterations discarded
\item \textbf{Samples}: 100--100,000 iterations depending on variance
\item \textbf{Statistics}: Median, P95, P99 reported
\item \textbf{GPU timing}: Blocking \texttt{waitUntilCompleted()} (synchronous)
\end{itemize}

\section{Results}

\subsection{Feature Coverage}

Table~\ref{tab:feature_coverage} shows the feature count distribution.

\begin{table}[t]
\caption{Feature Count Distribution (2,048 positions)}
\label{tab:feature_coverage}
\centering
\begin{tabular}{lr}
\toprule
Metric & Value \\
\midrule
Max features observed (total) & 60 \\
Max features per perspective & 30 \\
GPU limit per perspective & 64 \\
Positions exceeding limit & 0\% \\
\bottomrule
\end{tabular}
\end{table}

\subsection{GPU Dispatch Overhead}

Table~\ref{tab:dispatch} shows minimal-kernel dispatch overhead.

\begin{table}[t]
\caption{GPU Dispatch Overhead---Minimal Kernel (N=1,000)}
\label{tab:dispatch}
\centering
\begin{tabular}{lr}
\toprule
Statistic & Latency ($\mu$s) \\
\midrule
Median & 148 \\
P95 & 300 \\
P99 & 944 \\
\bottomrule
\end{tabular}
\end{table}

The 148~$\mu$s median dispatch overhead represents the minimum cost for any GPU operation in synchronous blocking mode.

\subsection{GPU Stage Breakdown}

Table~\ref{tab:stage_breakdown} decomposes end-to-end latency.

\begin{table}[t]
\caption{GPU Stage Breakdown (N=100 iterations each)}
\label{tab:stage_breakdown}
\centering
\begin{tabular}{lrrr}
\toprule
Batch Size & CPU Prep & GPU Eval & GPU \% \\
\midrule
1 & 0.2 $\mu$s & 283 $\mu$s & 99.9\% \\
8 & 0.3 $\mu$s & 278 $\mu$s & 99.9\% \\
512 & 6.3 $\mu$s & 419 $\mu$s & 98.5\% \\
\bottomrule
\end{tabular}
\end{table}

GPU dispatch and kernel execution dominate ($>$98\% of total time). CPU feature extraction is negligible due to zero-copy buffer management.

\subsection{Batch Latency Scaling}

Table~\ref{tab:batch_latency} shows end-to-end latency across batch sizes up to the maximum supported (4096).

\begin{table}[t]
\caption{GPU End-to-End Batch Latency (N=100 iterations)}
\label{tab:batch_latency}
\centering
\begin{tabular}{rrrrr}
\toprule
Batch & Median & P95 & P99 & Per-Pos \\
Size & ($\mu$s) & ($\mu$s) & ($\mu$s) & ($\mu$s) \\
\midrule
1 & 285 & 386 & 1,044 & 285.0 \\
8 & 279 & 424 & 1,179 & 34.8 \\
32 & 280 & 496 & 1,038 & 8.7 \\
64 & 282 & 501 & 1,041 & 4.4 \\
128 & 289 & 457 & 970 & 2.3 \\
256 & 311 & 448 & 1,244 & 1.2 \\
512 & 384 & 642 & 1,068 & 0.8 \\
1024 & 574 & 1,015 & 1,329 & 0.6 \\
2048 & 926 & 1,295 & 1,564 & 0.5 \\
3072 & 1,260 & 1,871 & 2,009 & 0.4 \\
4096 & 1,623 & 1,796 & 2,022 & 0.4 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key findings}: (1) Latency is approximately constant (279--311~$\mu$s) for batch sizes 1--256, showing dispatch dominance. (2) Per-position cost drops from 285~$\mu$s (N=1) to 0.4~$\mu$s (N=4096). (3) Latency increases linearly beyond N=512, indicating kernel compute becoming significant.

\subsection{True Batching Verification}

Table~\ref{tab:batching} compares sequential vs batched dispatches.

\begin{table}[t]
\caption{True Batching Verification (N=100 iterations)}
\label{tab:batching}
\centering
\begin{tabular}{rrrr}
\toprule
N & Sequential & Batched & Speedup \\
  & (N$\times$1 CB) & (1$\times$1 CB) & \\
\midrule
16 & 5,395 $\mu$s & 287 $\mu$s & 18.8$\times$ \\
64 & 21,051 $\mu$s & 305 $\mu$s & 69.0$\times$ \\
256 & 83,820 $\mu$s & 345 $\mu$s & 243.2$\times$ \\
1024 & 334,604 $\mu$s & 592 $\mu$s & 564.9$\times$ \\
\bottomrule
\end{tabular}
\end{table}

The sequential case creates N separate command buffers; the batched case uses one command buffer with two dispatches (feature transform + forward pass). Speedups scale super-linearly due to reduced per-dispatch overhead amortization.

\subsection{GPU Evaluation Correctness}

Table~\ref{tab:correctness} verifies GPU evaluation consistency.

\begin{table}[t]
\caption{GPU Evaluation Correctness (100 positions)}
\label{tab:correctness}
\centering
\begin{tabular}{lr}
\toprule
Metric & Value \\
\midrule
Non-zero GPU scores & 100\% \\
Consistent across runs & 100\% \\
Mean $|$GPU score$|$ & 188 \\
\bottomrule
\end{tabular}
\end{table}

GPU evaluation produces consistent, non-zero scores across repeated runs. Note: GPU uses NNUE weights while CPU baseline uses simple material+PST, so absolute values differ.

\section{Discussion}

\subsection{When GPU Evaluation Helps}

GPU batch evaluation becomes throughput-competitive at $N \geq 512$ (0.8~$\mu$s/position). This enables:
\begin{itemize}
\item \textbf{Database analysis}: Evaluating thousands of positions from game databases
\item \textbf{MCTS evaluation}: Monte Carlo Tree Search naturally batches leaf evaluations
\item \textbf{Training data generation}: Bulk position evaluation for neural network training
\item \textbf{Parallel analysis}: Evaluating multiple candidate moves simultaneously
\end{itemize}

\subsection{Alpha-Beta Limitations}

Single-position GPU blocking latency (285~$\mu$s) makes GPU evaluation unsuitable for alpha-beta search in synchronous blocking mode and without speculative evaluation. Alpha-beta search evaluates positions sequentially with data-dependent pruning, making batch accumulation impractical without significant architectural changes.

Our asynchronous evaluation API (\texttt{evaluate\_batch\_async}) enables CPU/GPU overlap, but the fundamental sequential nature of alpha-beta limits its applicability.

\subsection{Optimization Impact}

Table~\ref{tab:optimizations} summarizes our optimization contributions.

\begin{table}[t]
\caption{Optimization Summary}
\label{tab:optimizations}
\centering
\begin{tabular}{ll}
\toprule
Optimization & Benefit \\
\midrule
Zero-copy buffers & Eliminates allocation overhead \\
Dual-perspective kernel & Single dispatch for both perspectives \\
Adaptive selection & Optimal kernel per batch size \\
8-way unrolling & Improved ILP in FC0 \\
Threadgroup memory & Fast inter-thread communication \\
Async evaluation & CPU/GPU work overlap \\
\bottomrule
\end{tabular}
\end{table}

\section{Related Work}

Leela Chess Zero~\cite{LeelaChessZero2024} demonstrates successful GPU acceleration through MCTS, which naturally batches evaluations. AlphaZero~\cite{Silver2017} showed neural network evaluation can replace handcrafted evaluation with batch-oriented search.

For alpha-beta, Rocki and Suda~\cite{Rocki2010} explored GPU parallelization through parallel subtree evaluation. Our work extends this to unified memory hardware with optimized NNUE kernels.

Apple's Metal documentation~\cite{AppleMetal2024,AppleMetalBestPractices2024} recommends minimizing command buffer submissions and using threadgroup memory for intermediate results.

\section{Conclusion}

We presented MetalFish, a GPU-accelerated chess engine achieving:

\begin{enumerate}
\item \textbf{285~$\mu$s} median single-position blocking latency
\item \textbf{0.4~$\mu$s} per-position cost at batch size 4096
\item \textbf{565$\times$} true batching speedup at N=1024
\item \textbf{100\%} GPU evaluation consistency
\item \textbf{Zero-copy} buffer management via unified memory
\item \textbf{Adaptive} kernel selection for optimal performance
\item \textbf{Asynchronous} evaluation support for CPU/GPU overlap
\end{enumerate}

GPU acceleration is effective for batch-oriented workloads (MCTS, database analysis, training) but synchronous blocking dispatch overhead makes it unsuitable for alpha-beta's sequential evaluation pattern without speculative evaluation or asynchronous queuing. Our optimized Metal kernels with adaptive selection and zero-copy buffer management provide a solid foundation for GPU-accelerated chess evaluation on Apple Silicon.

\subsection*{Reproducibility}

\textbf{Hardware}: Apple M2 Max, 64GB. \textbf{Software}: macOS 14.0, Xcode 15.0. \textbf{Build}: CMake, -O3, LTO. \textbf{Source}: \url{https://github.com/NripeshN/MetalFish}. \textbf{Benchmark}: \texttt{gpubench} UCI command.

\begin{thebibliography}{10}

\bibitem{Stockfish2024}
Stockfish Developers: Stockfish 16 NNUE documentation.
\url{https://github.com/official-stockfish/Stockfish} (2024)

\bibitem{LeelaChessZero2024}
Leela Chess Zero: Neural network based chess engine.
\url{https://lczero.org/} (2024)

\bibitem{Silver2017}
Silver, D., et al.: Mastering chess and shogi by self-play with a general reinforcement learning algorithm.
arXiv:1712.01815 (2017)

\bibitem{Rocki2010}
Rocki, K., Suda, R.: Parallel minimax tree searching on GPU.
In: Parallel Processing and Applied Mathematics, LNCS vol. 6067, pp. 449--456. Springer (2010)

\bibitem{Nasu2018}
Nasu, Y.: Efficiently updatable neural-network-based evaluation functions for computer shogi.
The 28th World Computer Shogi Championship Appeal Document (2018)

\bibitem{AppleMetal2024}
Apple Inc.: Metal Programming Guide.
\url{https://developer.apple.com/metal/} (2024)

\bibitem{AppleMetalBestPractices2024}
Apple Inc.: Metal Best Practices Guide.
\url{https://developer.apple.com/library/archive/documentation/3DDrawing/Conceptual/MTLBestPracticesGuide/} (2024)

\bibitem{Knuth1975}
Knuth, D.E., Moore, R.W.: An analysis of alpha-beta pruning.
Artificial Intelligence 6(4), 293--326 (1975)

\end{thebibliography}

\end{document}
