%%%%%%%%%%%%%%%%%%%% MetalFish Paper %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% MetalFish: GPU-Accelerated Chess Engine on Apple Silicon
%
%%%%%%%%%%%%%%%% Springer %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass{svproc}

\usepackage{url}
\def\UrlFont{\rmfamily}
\usepackage{graphicx}
\usepackage{float}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{booktabs}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}

% C++ code listing style
\lstdefinestyle{cppstyle}{
    language=C++,
    backgroundcolor=\color{gray!5},
    basicstyle=\ttfamily\footnotesize,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    numberstyle=\tiny\color{gray},
    showstringspaces=false,
    tabsize=2,
    frame=single,
    keywordstyle=\color{blue!70!black},
    commentstyle=\color{green!50!black},
    stringstyle=\color{red!60!black},
    morekeywords={uint64_t, int32_t, int16_t, int8_t, uint, device, kernel, constant}
}

\begin{document}
\mainmatter

\title{MetalFish: A Hybrid MCTS-Alpha-Beta Chess Engine\\with GPU-Accelerated NNUE on Apple Silicon}

\titlerunning{MetalFish: Hybrid Search with GPU NNUE}

\author{Nripesh Niketan\inst{1}}

\authorrunning{N. Niketan}

\institute{Independent Researcher\\
\email{nripesh14@gmail.com}}

\maketitle

\begin{abstract}
We present MetalFish, a chess engine that combines Monte Carlo Tree Search (MCTS) with alpha-beta pruning, using GPU-accelerated NNUE evaluation on Apple Silicon's unified memory architecture. Our hybrid approach dynamically classifies positions and allocates search resources accordingly: MCTS for exploration, alpha-beta for tactical verification. On Apple M2 Max, our GPU NNUE implementation achieves 572$\times$ speedup through batch evaluation (0.3~$\mu$s/position at N=4096 vs 258~$\mu$s for single positions). MCTS achieves 259K nodes/second with 99\% transposition table hit rate; profiling shows selection (tree traversal) dominates at 96.3\% of iteration time, explaining why raw GPU throughput does not directly translate to search speed. We demonstrate that GPU dispatch overhead (140~$\mu$s median) makes single-position GPU evaluation unsuitable for pure alpha-beta search, but batch-oriented MCTS effectively amortizes this cost. The position classifier categorizes positions into five types with distinct search strategies. We use uniform policy priors with Dirichlet noise; a trained policy network would significantly improve MCTS efficiency. This work provides a framework for combining MCTS with alpha-beta on GPU-accelerated unified memory systems; playing strength validation against established engines is future work.

\keywords{Chess Engine, Hybrid Search, MCTS, Alpha-Beta, GPU Computing, Metal, NNUE, Apple Silicon}
\end{abstract}

\section{Introduction}

Modern chess engines have achieved superhuman strength through two distinct paradigms: Stockfish~\cite{Stockfish2024} uses alpha-beta search with NNUE evaluation, while Leela Chess Zero~\cite{LeelaChessZero2024} employs Monte Carlo Tree Search (MCTS) with deep neural networks. Each approach has complementary strengths: alpha-beta excels at tactical calculation with precise pruning, while MCTS provides robust strategic evaluation through self-play statistics.

This paper presents MetalFish, a hybrid chess engine that combines both search paradigms with GPU-accelerated NNUE evaluation on Apple Silicon. Our key insight is that \textit{position type} should determine search strategy: tactical positions benefit from alpha-beta's precise calculation, while strategic positions benefit from MCTS's exploratory nature.

Apple Silicon's unified memory architecture presents a unique opportunity for GPU acceleration: CPU and GPU share physical memory, eliminating explicit data transfers. However, as we demonstrate, GPU command buffer dispatch overhead (140~$\mu$s) dominates single-position latency, making GPU evaluation unsuitable for traditional alpha-beta search. MCTS, with its natural batching of leaf evaluations, effectively amortizes this overhead.

\subsection{Research Questions}

\begin{enumerate}
\item Can a hybrid MCTS-alpha-beta architecture leverage the strengths of both search paradigms?
\item How can GPU-accelerated NNUE evaluation be effectively integrated with MCTS on Apple Silicon?
\item What are the practical performance characteristics of such a hybrid system?
\end{enumerate}

\subsection{Contributions}

\begin{enumerate}
\item \textbf{Hybrid search architecture}: A novel combination of MCTS and alpha-beta with dynamic position classification and strategy selection.

\item \textbf{GPU NNUE integration}: Efficient batch evaluation achieving 572$\times$ speedup over sequential dispatches, with 100\% consistency across 1,000 positions.

\item \textbf{Position classifier}: Five-category classification (highly tactical to highly strategic) with distinct MCTS/alpha-beta weight allocation.

\item \textbf{Alpha-beta verifier}: Full PVS implementation with LMR, futility pruning, and history heuristics for tactical move verification.

\item \textbf{Quantified bottleneck analysis}: Stage-by-stage latency decomposition showing GPU dispatch accounts for $>$98\% of single-position time.
\end{enumerate}

\section{Background}

\subsection{Alpha-Beta Search}

Alpha-beta pruning~\cite{Knuth1975} is the foundation of traditional chess engines. It recursively explores the game tree, maintaining bounds ($\alpha$, $\beta$) to prune branches that cannot affect the final result. Modern implementations include:

\begin{itemize}
\item \textbf{Principal Variation Search (PVS)}: Searches the first move with full window, then uses null-window searches for remaining moves.
\item \textbf{Late Move Reductions (LMR)}: Reduces search depth for moves unlikely to be best.
\item \textbf{Futility Pruning}: Skips moves that cannot improve alpha given static evaluation.
\item \textbf{History Heuristics}: Improves move ordering based on past search statistics.
\end{itemize}

The critical limitation of alpha-beta is its sequential nature: each position must be evaluated before pruning decisions can be made, making \textit{latency} the critical metric.

\subsection{Monte Carlo Tree Search}

MCTS~\cite{Silver2017} builds a search tree through repeated simulations, each consisting of four phases:

\begin{enumerate}
\item \textbf{Selection}: Traverse tree using UCT (Upper Confidence bounds for Trees) to balance exploration and exploitation.
\item \textbf{Expansion}: Add new nodes at leaf positions.
\item \textbf{Evaluation}: Assess leaf positions using neural network or other evaluation.
\item \textbf{Backpropagation}: Update statistics along the path from leaf to root.
\end{enumerate}

MCTS naturally batches leaf evaluations, making \textit{throughput} the critical metric. This property makes MCTS well-suited for GPU acceleration.

\subsection{NNUE Architecture}

Stockfish's NNUE (Efficiently Updatable Neural Network)~\cite{Nasu2018} uses HalfKAv2\_hm features with sparse input. Table~\ref{tab:nnue_arch} summarizes the architecture.

\begin{table}[t]
\caption{NNUE Network Architecture}
\label{tab:nnue_arch}
\centering
\begin{tabular}{lrr}
\toprule
Component & Big Network & Small Network \\
\midrule
Feature set & HalfKAv2\_hm & HalfKAv2\_hm \\
Input features & 45,056 & 22,528 \\
Hidden dimension & 1,024 & 128 \\
FC0 output & 15 (+1 skip) & 15 (+1 skip) \\
FC1 output & 32 & 32 \\
FC2 output & 1 & 1 \\
Layer stacks (buckets) & 8 & 8 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Metal Compute Model}

Apple Metal~\cite{AppleMetal2024} provides GPU compute with unified memory:
\begin{itemize}
\item \textbf{Unified memory}: CPU and GPU share physical memory, eliminating explicit transfers
\item \textbf{Command buffer lifecycle}: Allocation $\rightarrow$ encoding $\rightarrow$ commit $\rightarrow$ waitUntilCompleted
\item \textbf{Dispatch overhead}: Each command buffer submission incurs fixed overhead (140~$\mu$s median on M2 Max)
\end{itemize}

\section{System Architecture}

MetalFish implements a three-layer architecture: (1) position classification, (2) hybrid search orchestration, and (3) GPU-accelerated evaluation.

\subsection{Position Classifier}

The position classifier analyzes board features to determine position type:

\begin{lstlisting}[style=cppstyle,caption={Position classification}]
enum class PositionType {
  HIGHLY_TACTICAL,  // In check, many captures
  TACTICAL,         // Forcing moves available
  BALANCED,         // Mixed characteristics
  STRATEGIC,        // Quiet, positional play
  HIGHLY_STRATEGIC  // Closed position, maneuvering
};
\end{lstlisting}

Classification considers:
\begin{itemize}
\item \textbf{Check status}: Positions in check are highly tactical
\item \textbf{Capture count}: Many available captures indicate tactical nature
\item \textbf{Hanging pieces}: Undefended pieces suggest tactical opportunities
\item \textbf{Pawn structure}: Closed positions favor strategic play
\item \textbf{King safety}: Exposed kings increase tactical potential
\end{itemize}

\subsection{Strategy Selection}

Each position type maps to a search strategy with specific MCTS/alpha-beta weights:

\begin{table}[t]
\caption{Position Type to Search Strategy Mapping}
\label{tab:strategy}
\centering
\begin{tabular}{lrrr}
\toprule
Position Type & MCTS & AB & Verify Depth \\
\midrule
Highly Tactical & 15\% & 85\% & 10 \\
Tactical & 25\% & 75\% & 8 \\
Balanced & 25\% & 75\% & 6 \\
Strategic & 32\% & 67\% & 4 \\
Highly Strategic & 40\% & 60\% & 4 \\
\bottomrule
\end{tabular}
\end{table}

The MCTS weight determines time allocation for the MCTS phase, while the AB weight influences verification depth and override thresholds.

\subsection{Hybrid Search Pipeline}

Algorithm~\ref{alg:hybrid} shows the hybrid search pipeline.

\begin{algorithm}[t]
\caption{Hybrid MCTS-Alpha-Beta Search}
\label{alg:hybrid}
\begin{algorithmic}[1]
\Require Position $p$, time budget $T$
\Ensure Best move $m$
\State $type \gets$ \Call{ClassifyPosition}{$p$}
\State $strategy \gets$ \Call{SelectStrategy}{$type$}
\State $T_{mcts} \gets T \times strategy.mcts\_weight$
\State $T_{ab} \gets T - T_{mcts}$
\State \textbf{// Phase 1: MCTS exploration}
\State $m_{mcts} \gets$ \Call{RunMCTS}{$p$, $T_{mcts}$}
\If{$strategy.ab\_weight > 0.1$}
    \State \textbf{// Phase 2: Alpha-beta verification}
    \State $result \gets$ \Call{VerifyWithAB}{$p$, $m_{mcts}$, $strategy.depth$}
    \If{$result.override$ \textbf{and} $result.score\_diff > threshold$}
        \State \Return $result.ab\_move$
    \EndIf
\EndIf
\State \Return $m_{mcts}$
\end{algorithmic}
\end{algorithm}

\subsection{MCTS Implementation}

Our MCTS implementation uses PUCT (Predictor + UCT) for node selection:

\begin{equation}
PUCT(s, a) = Q(s, a) + c_{puct} \cdot P(s, a) \cdot \frac{\sqrt{N(s)}}{1 + N(s, a)}
\end{equation}

where $Q(s, a)$ is the action value, $P(s, a)$ is the prior probability, $N(s)$ is the parent visit count, and $N(s, a)$ is the edge visit count.

\textbf{Important limitation}: We use \textit{uniform policy priors} ($P(s, a) = 1/|A|$ for all legal moves $a$), not a trained policy network. This makes our MCTS similar to UCT with exploration noise. A trained policy network would significantly improve search efficiency by focusing exploration on promising moves.

Key implementation features:
\begin{itemize}
\item \textbf{Uniform priors}: All legal moves have equal prior probability
\item \textbf{Dirichlet noise}: Added at root for exploration ($\alpha = 0.3$, $\epsilon = 0.25$)
\item \textbf{Virtual loss}: Prevents multiple threads from selecting the same path
\item \textbf{Tree reuse}: Previous search tree preserved between moves
\item \textbf{MCTS transposition table}: Caches evaluations across searches (99\% hit rate observed)
\end{itemize}

\subsection{Alpha-Beta Verifier}

The alpha-beta component provides tactical verification with full search features:

\begin{itemize}
\item \textbf{Principal Variation Search}: Full window for first move, null-window for rest
\item \textbf{Aspiration windows}: Narrow search window based on previous score
\item \textbf{Late Move Reductions}: Depth reduction for late moves in move ordering
\item \textbf{Futility pruning}: Skip moves that cannot improve alpha
\item \textbf{Quiescence search}: Extend search until position is quiet
\item \textbf{Killer moves}: Two killer moves per ply for move ordering
\item \textbf{History heuristics}: Score moves by historical success
\end{itemize}

\subsection{GPU NNUE Integration}

Table~\ref{tab:gpu_constants} shows GPU configuration parameters.

\begin{table}[t]
\caption{GPU Configuration Constants}
\label{tab:gpu_constants}
\centering
\begin{tabular}{lr}
\toprule
Parameter & Value \\
\midrule
Max batch size & 4,096 \\
Max features per perspective & 64 \\
Threadgroup size & 256 \\
SIMD group size & 32 \\
Forward pass threads & 64 \\
\bottomrule
\end{tabular}
\end{table}

We implement adaptive kernel selection:
\begin{itemize}
\item \textbf{CPU fallback}: Batch size $< 4$
\item \textbf{GPU standard}: Batch size $< 64$
\item \textbf{GPU SIMD}: Batch size $\geq 64$ with dual-perspective kernels
\end{itemize}

Command buffer optimizations:
\begin{itemize}
\item Unretained references to avoid retain/release overhead
\item Hazard tracking disabled for unified memory buffers
\item Pre-allocated buffers to avoid per-dispatch allocation
\end{itemize}

\section{Experimental Methodology}

\subsection{Hardware and Software}

\begin{itemize}
\item \textbf{Hardware}: Apple M2 Max (12-core CPU, 38-core GPU, 64GB unified memory)
\item \textbf{Software}: macOS 14.0, Xcode 15.0, Metal 3.0
\item \textbf{Build}: CMake, -O3, LTO enabled
\item \textbf{Networks}: nn-c288c895ea92.nnue (125MB big), nn-37f18f62d772.nnue (6MB small)
\end{itemize}

\subsection{Benchmark Dataset}

Our benchmark uses 32 unique FEN positions representing diverse game phases:
\begin{itemize}
\item 4 opening positions (32 pieces)
\item 10 middlegame positions (28--32 pieces)
\item 4 tactical positions (complex piece interactions)
\item 14 endgame positions (2--20 pieces)
\end{itemize}

\subsection{Timing Methodology}

\begin{itemize}
\item \textbf{Timer}: \texttt{std::chrono::high\_resolution\_clock}
\item \textbf{Warmup}: 100 iterations discarded
\item \textbf{Samples}: 100 iterations per measurement
\item \textbf{Statistics}: Median, P95, P99 reported
\item \textbf{GPU timing}: Blocking \texttt{waitUntilCompleted()} (synchronous)
\end{itemize}

\subsection{Hybrid Search Evaluation}

We evaluate the hybrid search on positions from multiple game phases:
\begin{itemize}
\item \textbf{Opening}: Standard opening positions (e.g., Italian Game)
\item \textbf{Middlegame}: Complex positions with multiple piece interactions
\item \textbf{Endgame}: Simplified positions (KRK, KQK)
\end{itemize}

Search time is fixed at 5 seconds per position to allow meaningful MCTS exploration.

\section{Results}

\subsection{Hybrid Search Performance}

Table~\ref{tab:hybrid_perf} shows hybrid search performance across position types.

\begin{table}[t]
\caption{Hybrid Search Performance by Position Type}
\label{tab:hybrid_perf}
\centering
\begin{tabular}{lrrr}
\toprule
Position Type & MCTS Nodes & NPS & Time (ms) \\
\midrule
Highly Strategic & 443,511 & 277K & 1,600 \\
Strategic & 178,776 & 244K & 731 \\
Balanced & 164,756 & 219K & 750 \\
Endgame (KRK) & 127,440 & 283K & 450 \\
\bottomrule
\end{tabular}
\end{table}

The MCTS component achieves 190K--283K nodes per second, with throughput varying based on position complexity and tree structure.

\subsection{MCTS Profiling Breakdown}

Table~\ref{tab:mcts_profile} shows where time is spent during MCTS search, explaining why throughput is 259K nodes/second rather than the millions suggested by raw GPU evaluation speed.

\begin{table}[t]
\caption{MCTS Time Breakdown (3 second search, starting position)}
\label{tab:mcts_profile}
\centering
\begin{tabular}{lrr}
\toprule
Phase & Time \% & Description \\
\midrule
Selection & 96.3\% & Tree traversal with PUCT \\
Expansion & 2.6\% & Move generation, node creation \\
Evaluation & 0.4\% & GPU NNUE (mostly TT hits) \\
Backpropagation & 0.8\% & Statistics update \\
\midrule
Total nodes & \multicolumn{2}{r}{776,167} \\
NPS & \multicolumn{2}{r}{258,718} \\
TT hit rate & \multicolumn{2}{r}{99.0\%} \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key finding}: Selection dominates at 96.3\% because each MCTS iteration traverses the tree from root to leaf. The MCTS transposition table achieves 99\% hit rate, reducing evaluation time to just 0.4\%. This explains the apparent discrepancy between GPU batch throughput (0.3~$\mu$s/position at N=4096) and MCTS throughput (259K nodes/second): most time is spent in tree traversal, not evaluation.

\textbf{Definition}: An MCTS ``node'' in our throughput measurement represents one complete iteration: selection from root to leaf, expansion of the leaf node, evaluation (often cached), and backpropagation of the result.

\subsection{Position Classification Results}

Table~\ref{tab:classification} shows position classification for benchmark positions.

\begin{table}[t]
\caption{Position Classification Examples}
\label{tab:classification}
\centering
\begin{tabular}{lll}
\toprule
Position & Classification & Strategy \\
\midrule
Starting position & Highly Strategic & 40\% MCTS, 60\% AB \\
Italian Game (move 4) & Strategic & 32\% MCTS, 67\% AB \\
Central tension & Balanced & 25\% MCTS, 75\% AB \\
KRK endgame & Balanced & 20\% MCTS, 80\% AB \\
\bottomrule
\end{tabular}
\end{table}

\subsection{GPU Dispatch Overhead}

Table~\ref{tab:dispatch} shows minimal-kernel dispatch overhead.

\begin{table}[t]
\caption{GPU Dispatch Overhead---Minimal Kernel (N=1,000)}
\label{tab:dispatch}
\centering
\begin{tabular}{lr}
\toprule
Statistic & Latency ($\mu$s) \\
\midrule
Median & 140.6 \\
P95 & 265.0 \\
P99 & 334.7 \\
\bottomrule
\end{tabular}
\end{table}

The 140~$\mu$s median dispatch overhead represents the irreducible minimum cost for any GPU operation in synchronous blocking mode.

\subsection{GPU Stage Breakdown}

Table~\ref{tab:stage_breakdown} decomposes end-to-end GPU latency into stages.

\begin{table}[t]
\caption{GPU Stage Breakdown (median, N=100 iterations)}
\label{tab:stage_breakdown}
\centering
\begin{tabular}{lrrrr}
\toprule
Batch & CPU Prep & GPU Eval & Total & GPU \% \\
Size & ($\mu$s) & ($\mu$s) & ($\mu$s) & \\
\midrule
1 & 0.2 & 262.0 & 262.2 & 99.9\% \\
8 & 0.3 & 271.2 & 271.5 & 99.9\% \\
512 & 6.0 & 348.5 & 354.5 & 98.3\% \\
\bottomrule
\end{tabular}
\end{table}

GPU dispatch and synchronization dominate ($>$98\% of total time). CPU feature extraction is negligible due to zero-copy buffer management.

\subsection{Batch Latency Scaling}

Table~\ref{tab:batch_latency} shows end-to-end latency across batch sizes.

\begin{table}[t]
\caption{GPU End-to-End Batch Latency (N=100 iterations)}
\label{tab:batch_latency}
\centering
\begin{tabular}{rrrrr}
\toprule
Batch & Median & P95 & P99 & Per-Pos \\
Size & ($\mu$s) & ($\mu$s) & ($\mu$s) & ($\mu$s) \\
\midrule
1 & 258.8 & 375.3 & 496.0 & 258.8 \\
8 & 261.6 & 360.0 & 407.1 & 32.7 \\
64 & 280.5 & 410.5 & 1669.0 & 4.4 \\
256 & 303.0 & 440.2 & 1408.0 & 1.2 \\
512 & 362.2 & 495.0 & 1721.5 & 0.7 \\
1024 & 503.6 & 618.2 & 689.2 & 0.5 \\
2048 & 788.7 & 911.3 & 2279.8 & 0.4 \\
4096 & 1,360.3 & 1,464.5 & 1,536.0 & 0.3 \\
\bottomrule
\end{tabular}
\end{table}

Per-position cost drops from 258~$\mu$s (N=1) to 0.3~$\mu$s (N=4096), demonstrating effective amortization of dispatch overhead.

\subsection{True Batching Verification}

Table~\ref{tab:batching} compares sequential vs batched dispatches.

\begin{table}[t]
\caption{True Batching Verification (N=50 iterations)}
\label{tab:batching}
\centering
\begin{tabular}{rrrr}
\toprule
N & Sequential & Batched & Speedup \\
  & (N$\times$1 CB) & (1$\times$1 CB) & \\
\midrule
16 & 4,415~$\mu$s & 259~$\mu$s & 17.0$\times$ \\
64 & 18,975~$\mu$s & 282~$\mu$s & 67.2$\times$ \\
256 & 74,989~$\mu$s & 309~$\mu$s & 242.7$\times$ \\
1024 & 306,066~$\mu$s & 534~$\mu$s & 572.3$\times$ \\
\bottomrule
\end{tabular}
\end{table}

Speedups scale approximately linearly with batch size because each sequential dispatch incurs the full dispatch overhead.

\subsection{GPU Evaluation Consistency}

Table~\ref{tab:correctness} verifies GPU evaluation reproducibility.

\begin{table}[t]
\caption{GPU Evaluation Consistency (1,000 positions)}
\label{tab:correctness}
\centering
\begin{tabular}{lr}
\toprule
Metric & Value \\
\midrule
Non-zero GPU scores & 100\% \\
Consistent across runs & 100\% \\
Mean $|$score$|$ & 221.6 \\
Score range & [-407, 258] \\
\bottomrule
\end{tabular}
\end{table}

GPU evaluation produces consistent, non-zero scores across repeated runs.

\section{Discussion}

\subsection{Why Hybrid Search?}

The fundamental insight driving our hybrid architecture is that different position types benefit from different search paradigms:

\begin{itemize}
\item \textbf{Tactical positions}: Alpha-beta's precise pruning excels at calculating forcing sequences. A hanging piece or checkmate threat requires exact calculation, not statistical estimation.

\item \textbf{Strategic positions}: MCTS's exploratory nature handles quiet positions well, where many moves are roughly equal and long-term planning matters more than immediate tactics.
\end{itemize}

Our position classifier bridges these paradigms, dynamically allocating search resources based on position characteristics.

\subsection{GPU Acceleration Trade-offs}

GPU dispatch overhead (140~$\mu$s) makes single-position GPU evaluation unsuitable for pure alpha-beta search. However, MCTS naturally batches leaf evaluations, effectively amortizing this overhead:

\begin{itemize}
\item At batch size 1: 258~$\mu$s/position (dominated by dispatch)
\item At batch size 4096: 0.3~$\mu$s/position (compute-dominated)
\end{itemize}

Our MCTS implementation achieves 190K--280K nodes/second by leveraging this batching, with GPU NNUE providing high-quality evaluations.

\subsection{Alpha-Beta Verification Benefits}

The alpha-beta verifier provides several benefits:

\begin{enumerate}
\item \textbf{Tactical oversight}: Catches tactical errors that MCTS might miss due to insufficient exploration.

\item \textbf{Move validation}: Verifies MCTS's best move against alpha-beta's recommendation.

\item \textbf{Policy improvement}: Alpha-beta search results inform move ordering and policy priors.
\end{enumerate}

In our experiments, the verifier rarely overrides MCTS (0 overrides in benchmark positions), suggesting MCTS produces reasonable moves. However, the verifier provides confidence that tactical blunders are caught.

\subsection{Limitations}

\begin{itemize}
\item \textbf{Single-threaded MCTS}: Our current implementation uses single-threaded MCTS due to Position object thread-safety constraints. Multi-threaded MCTS would significantly increase throughput.

\item \textbf{Policy network}: We use uniform policy priors with Dirichlet noise. A trained policy network would improve MCTS efficiency.

\item \textbf{Synchronous GPU}: We use blocking GPU dispatch. Asynchronous dispatch with completion handlers could enable CPU/GPU overlap.
\end{itemize}

\subsection{Future Work}

\begin{enumerate}
\item \textbf{Multi-threaded MCTS}: Thread-safe position representation for parallel tree search.

\item \textbf{Policy network training}: Train a policy network on MCTS self-play data.

\item \textbf{Asynchronous evaluation}: Overlap CPU search with GPU evaluation.

\item \textbf{Deeper AB integration}: Use alpha-beta bounds to prune MCTS subtrees.
\end{enumerate}

\section{Related Work}

\subsection{Hybrid Search Approaches}

AlphaZero~\cite{Silver2017} demonstrated that MCTS with neural network evaluation can achieve superhuman play. However, AlphaZero uses pure MCTS without alpha-beta verification.

Leela Chess Zero~\cite{LeelaChessZero2024} implements AlphaZero's approach as an open-source project, achieving top-tier strength through self-play training and MCTS search.

Stockfish~\cite{Stockfish2024} represents the state-of-the-art in alpha-beta engines, using NNUE evaluation with highly optimized search. Our alpha-beta verifier draws inspiration from Stockfish's search techniques.

\subsection{GPU Chess Engines}

Rocki and Suda~\cite{Rocki2010} explored GPU parallelization of minimax through parallel subtree evaluation. Their work predates modern unified memory architectures.

Our work extends GPU chess engine research to Apple Silicon's unified memory architecture, providing quantified bottleneck analysis and demonstrating that MCTS is better suited for GPU acceleration than alpha-beta due to natural batching.

\subsection{Neural Network Evaluation}

NNUE (Efficiently Updatable Neural Network)~\cite{Nasu2018} revolutionized chess engine evaluation by providing neural network quality with efficient incremental updates. Our GPU implementation preserves NNUE's architecture while enabling batch evaluation.

Apple's Metal documentation~\cite{AppleMetal2024,AppleMetalBestPractices2024} provides guidance on GPU compute optimization, including command buffer management and unified memory usage.

\section{Conclusion}

We presented MetalFish, a hybrid chess engine combining MCTS with alpha-beta search and GPU-accelerated NNUE evaluation on Apple Silicon. Our key findings:

\begin{enumerate}
\item \textbf{Hybrid architecture}: Position classification enables dynamic allocation between MCTS exploration (40\% for strategic positions) and alpha-beta verification (up to 85\% for tactical positions).

\item \textbf{MCTS throughput}: 259K nodes/second with GPU NNUE evaluation. Profiling shows selection (tree traversal) dominates at 96.3\%, with 99\% TT hit rate reducing evaluation overhead.

\item \textbf{GPU batch efficiency}: 572$\times$ speedup through batching (0.3~$\mu$s/position at N=4096 vs 258~$\mu$s for single positions).

\item \textbf{Dispatch overhead}: 140~$\mu$s irreducible minimum makes GPU unsuitable for pure alpha-beta but effective for batch-oriented MCTS.

\item \textbf{Evaluation consistency}: 100\% reproducibility across 1,000 positions with meaningful score differentiation.
\end{enumerate}

\textbf{Limitations}: We use uniform policy priors, which limits MCTS efficiency compared to engines with trained policy networks. Playing strength has not been validated against established engines; this is future work.

\textbf{Key insight}: The hybrid MCTS-alpha-beta architecture provides a framework for combining strategic exploration with tactical precision on GPU-accelerated unified memory systems. The primary bottleneck is tree traversal (selection), not GPU evaluation, suggesting that algorithmic improvements to MCTS selection would have greater impact than further GPU optimization.

\subsection*{Reproducibility}

\textbf{Hardware}: Apple M2 Max, 64GB. \textbf{Software}: macOS 14.0, Xcode 15.0. \textbf{Build}: CMake, -O3, LTO. \textbf{Source}: \url{https://github.com/NripeshN/MetalFish}. \textbf{Benchmarks}: \texttt{gpubench} and \texttt{mcts} UCI commands.

\begin{thebibliography}{10}

\bibitem{Stockfish2024}
Stockfish Developers: Stockfish 16 NNUE documentation.
\url{https://github.com/official-stockfish/Stockfish} (2024)

\bibitem{LeelaChessZero2024}
Leela Chess Zero: Neural network based chess engine.
\url{https://lczero.org/} (2024)

\bibitem{Silver2017}
Silver, D., et al.: Mastering chess and shogi by self-play with a general reinforcement learning algorithm.
arXiv:1712.01815 (2017)

\bibitem{Rocki2010}
Rocki, K., Suda, R.: Parallel minimax tree searching on GPU.
In: Parallel Processing and Applied Mathematics, LNCS vol. 6067, pp. 449--456. Springer (2010)

\bibitem{Nasu2018}
Nasu, Y.: Efficiently updatable neural-network-based evaluation functions for computer shogi.
The 28th World Computer Shogi Championship Appeal Document (2018)

\bibitem{AppleMetal2024}
Apple Inc.: Metal Programming Guide.
\url{https://developer.apple.com/metal/} (2024)

\bibitem{AppleMetalBestPractices2024}
Apple Inc.: Metal Best Practices Guide.
\url{https://developer.apple.com/library/archive/documentation/3DDrawing/Conceptual/MTLBestPracticesGuide/} (2024)

\bibitem{Knuth1975}
Knuth, D.E., Moore, R.W.: An analysis of alpha-beta pruning.
Artificial Intelligence 6(4), 293--326 (1975)

\end{thebibliography}

\end{document}
